{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "## Import TensorFlow and NumPy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import cifar10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure DNN settings\n",
    "\n",
    "Here, we specify the ResNet architecture parameters:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Number of classes to infer\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Depth parameter\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset and preprocess\n",
    "\n",
    "We are working with the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load trained ResNet model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Load model\n",
    "model_name = 'weight_quant_4b_final_3'\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d_%s' % (depth, version, model_name)\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), model_type)\n",
    "model_full_name = 'cifar10_%s_model' % model_type\n",
    "filepath = os.path.join(save_dir, model_full_name)\n",
    "\n",
    "# Load model checkpoint\n",
    "K.clear_session()\n",
    "model = load_model(filepath)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ResNet20v1_weight_quant_4b_final_3\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Save all model parameters to a dict\n",
    "weights = {}\n",
    "for olayer in model.layers:\n",
    "    weights[olayer.name] = olayer.get_weights()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# Perform baseline inference\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 34/313 [==>...........................] - ETA: 21s - loss: 1.9078 - accuracy: 0.5708"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-3acd16fbd002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform baseline inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "# RRAM confusion matrices for 4 levels per cell\n",
    "\n",
    "# # Tech A\n",
    "# # relax_mat = np.identity(4)\n",
    "# # Tech B\n",
    "# relax_mat = np.array([[99.1, 0.9, 0., 0.],\n",
    "#                       [0.2, 99.6, 0.2, 0.],\n",
    "#                       [0., 1.0, 99.0, 0.],\n",
    "#                       [0., 0., 0.3, 99.7]]) / 100\n",
    "\n",
    "# # Tech C\n",
    "# # relax_mat = np.array([[98.2, 1.8, 0., 0.],\n",
    "# #                       [2.2, 95.2, 2.6, 0.],\n",
    "# #                       [0., 5.7, 92.4, 1.9],\n",
    "# #                       [0., 0.3, 4.3, 95.4]]) / 100\n",
    "# print(relax_mat)\n",
    "# print(np.sum(relax_mat, axis=1))\n",
    "\n",
    "full_relax_mat = np.load('confmats/techC/100000.npy')\n",
    "\n",
    "# gmax = 128e-6\n",
    "# best_levels = [0, 7, 23, 31]\n",
    "# best_levels = [0, 6, 24, 31]\n",
    "# best_thresh = [0, 11.56873747e-6, 61.22965932e-6, 110.32625251e-6, gmax]\n",
    "pushout = 6\n",
    "gmax = 40e-6\n",
    "best_levels = [0, 12-pushout, 22+pushout, 31]\n",
    "best_thresh = [0, 4.40881764e-6, 20.36873747e-6, 32.09619238e-6, gmax]\n",
    "best_thresh_levels = np.int32(np.round(np.array(best_thresh) / gmax * 32))\n",
    "print(best_thresh_levels)\n",
    "\n",
    "print(\"Full confusion matrix:\")\n",
    "print(full_relax_mat)\n",
    "\n",
    "relax_mat = []\n",
    "relax_mat_best = full_relax_mat[:, best_levels]\n",
    "# print(relax_mat_best)\n",
    "\n",
    "# Apply thresholds\n",
    "for i in range(4):\n",
    "    i_lo, i_hi = best_thresh_levels[i], best_thresh_levels[i+1]\n",
    "    relax_mat.append(np.sum(relax_mat_best[i_lo:i_hi, :], axis=0))\n",
    "\n",
    "# Normalize confusion matrix\n",
    "relax_mat = np.array(relax_mat)\n",
    "relax_mat = relax_mat / relax_mat.sum(axis=1)[:, np.newaxis]\n",
    "lsber = np.mean([relax_mat[1,0], relax_mat[0,1], relax_mat[2,3], relax_mat[3,2]])\n",
    "msber = np.mean([relax_mat[1,2], relax_mat[2,1]])\n",
    "\n",
    "print(\"Reduced confusion matrix:\")\n",
    "print(relax_mat)\n",
    "print(lsber, msber)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  4 16 26 32]\n",
      "Full confusion matrix:\n",
      "[[351 123  48 ...   0   0   0]\n",
      " [ 97 199 145 ...   0   0   0]\n",
      " [ 38  93 132 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  78  94  85]\n",
      " [  0   0   0 ...  37  83  78]\n",
      " [  0   0   0 ...  27  65 146]]\n",
      "Reduced confusion matrix:\n",
      "[[0.82914573 0.16917923 0.00167504 0.        ]\n",
      " [0.0195599  0.97066015 0.00733496 0.00244499]\n",
      " [0.         0.0310559  0.83229814 0.13664596]\n",
      " [0.         0.         0.45336788 0.54663212]]\n",
      "0.1946882425154534 0.019195431973150694\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "# Create weight matrices after RRAM relaxation according to the confusion matrices (4 levels per cell)\n",
    "\n",
    "# Whether to assign two MSBs to two different RRAM cells\n",
    "INTERLEAVING = True\n",
    "\n",
    "if INTERLEAVING:\n",
    "    levels_0 = [-8, -6, 0, 2]\n",
    "    levels_1 = [0, 1, 4, 5]\n",
    "else:\n",
    "    levels_0 = [-8, -4, 0, 4]\n",
    "    levels_1 = [0, 1, 2, 3]\n",
    "\n",
    "weights_relax = {}\n",
    "for layer_name in weights:\n",
    "    if 'conv2d' in layer_name or 'dense' in layer_name:\n",
    "        print(layer_name)\n",
    "        W, b, W_max = weights[layer_name]\n",
    "        W_quant = tf.quantization.fake_quant_with_min_max_args(W, -W_max, W_max, 4, narrow_range=True).numpy()\n",
    "        W_relax = np.zeros_like(W)\n",
    "        W_full_range = tf.quantization.fake_quant_with_min_max_args(np.linspace(-W_max, W_max, 32), -W_max, W_max, 4, narrow_range=True).numpy()\n",
    "        W_quant_level = np.unique(W_full_range)\n",
    "        assert(len(W_quant_level) == 15)\n",
    "        for i in range(1, 16):\n",
    "            if INTERLEAVING:\n",
    "                sel0 = ((i >> 2) & 0b10) | ((i >> 1) & 0b1)\n",
    "                sel1 = ((i >> 1) & 0b10) | (i & 0b1)\n",
    "            else:\n",
    "                sel0 = ((i >> 2) & 0b10) | ((i >> 2) & 0b1)\n",
    "                sel1 = (i & 0b10) | (i & 0b1)\n",
    "            W_mask = (W_quant == W_quant_level[i-1])\n",
    "            part0 = np.random.choice(levels_0, np.sum(W_mask), p=relax_mat[sel0])\n",
    "            part1 = np.random.choice(levels_1, np.sum(W_mask), p=relax_mat[sel1])\n",
    "            W_relax[W_mask] = (part0 + part1) / 7 * W_max\n",
    "        weights_relax[layer_name] = W_relax\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv2d_noise\n",
      "conv2d_noise_1\n",
      "conv2d_noise_2\n",
      "conv2d_noise_3\n",
      "conv2d_noise_4\n",
      "conv2d_noise_5\n",
      "conv2d_noise_6\n",
      "conv2d_noise_7\n",
      "conv2d_noise_8\n",
      "conv2d_noise_9\n",
      "conv2d_noise_10\n",
      "conv2d_noise_11\n",
      "conv2d_noise_12\n",
      "conv2d_noise_13\n",
      "conv2d_noise_14\n",
      "conv2d_noise_15\n",
      "conv2d_noise_16\n",
      "conv2d_noise_17\n",
      "conv2d_noise_18\n",
      "conv2d_noise_19\n",
      "conv2d_noise_20\n",
      "dense_noise\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "# Load relaxed weights back to the model\n",
    "for layer in model.layers:\n",
    "    if layer.name in weights_relax:\n",
    "        print(layer.name)\n",
    "        W, b, W_max = layer.get_weights()\n",
    "        W_relax = weights_relax[layer.name]\n",
    "        layer.set_weights([W_relax, b, W_max])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv2d_noise\n",
      "conv2d_noise_1\n",
      "conv2d_noise_2\n",
      "conv2d_noise_3\n",
      "conv2d_noise_4\n",
      "conv2d_noise_5\n",
      "conv2d_noise_6\n",
      "conv2d_noise_7\n",
      "conv2d_noise_8\n",
      "conv2d_noise_9\n",
      "conv2d_noise_10\n",
      "conv2d_noise_11\n",
      "conv2d_noise_12\n",
      "conv2d_noise_13\n",
      "conv2d_noise_14\n",
      "conv2d_noise_15\n",
      "conv2d_noise_16\n",
      "conv2d_noise_17\n",
      "conv2d_noise_18\n",
      "conv2d_noise_19\n",
      "conv2d_noise_20\n",
      "dense_noise\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "# Evaluate accuracy after relaxation\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 21s 66ms/step - loss: 2.5722 - accuracy: 0.1000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "# FINAL RESULT\n",
    "pd.DataFrame([[pushout, INTERLEAVING, accuracy, lsber, msber]], columns=[\"Pushout\", \"Interleaving\", \"Accuracy\", \"LSBER\", \"MSBER\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pushout</th>\n",
       "      <th>Interleaving</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>LSBER</th>\n",
       "      <th>MSBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.194688</td>\n",
       "      <td>0.019195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pushout  Interleaving  Accuracy     LSBER     MSBER\n",
       "0        6          True       0.1  0.194688  0.019195"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the confusion matrix for 16 levels per cell\n",
    "relax_mat = np.load('confmats/techA/100.npy').T\n",
    "relax_mat = relax_mat / np.sum(relax_mat, axis=1).reshape([16, 1])\n",
    "print(relax_mat)\n",
    "print(np.sum(relax_mat, axis=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create weight matrices after RRAM relaxation according to the confusion matrices (16 levels per cell)\n",
    "levels = np.arange(-8, 8)\n",
    "weights_relax = {}\n",
    "for layer_name in weights:\n",
    "    if 'conv2d' in layer_name or 'dense' in layer_name:\n",
    "        print(layer_name)\n",
    "        W, b, W_max = weights[layer_name]\n",
    "        W_quant = tf.quantization.fake_quant_with_min_max_args(W, -W_max, W_max, 4, narrow_range=True).numpy()\n",
    "        W_relax = np.zeros_like(W)\n",
    "        W_full_range = tf.quantization.fake_quant_with_min_max_args(np.linspace(-W_max, W_max, 32), -W_max, W_max, 4, narrow_range=True).numpy()\n",
    "        W_quant_level = np.unique(W_full_range)\n",
    "        assert(len(W_quant_level) == 15)\n",
    "        for i in range(1, 16):\n",
    "            W_mask = (W_quant == W_quant_level[i-1])\n",
    "            W_int = np.random.choice(levels, np.sum(W_mask), p=relax_mat[i])\n",
    "            W_relax[W_mask] = W_int / 7 * W_max\n",
    "        weights_relax[layer_name] = W_relax\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load relaxed weights back to the model\n",
    "for layer in model.layers:\n",
    "    if layer.name in weights_relax:\n",
    "        print(layer.name)\n",
    "        W, b, W_max = layer.get_weights()\n",
    "        W_relax = weights_relax[layer.name]\n",
    "        layer.set_weights([W_relax, b, W_max])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate accuracy after relaxation\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "f85c0ae1067a86ad6a96b144378883e79fd1516474b579ba33ee3a7084540002"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}